
{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Imports\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "V3OVfVMQKAkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📚 Top 50 SIFT Correspondences Between Book Image and Video Frame\n",
        "\n",
        "This cell defines the function `get_top_50_correspondences`, which identifies and visualizes the top 50 SIFT feature matches between a given book cover image and the first frame of a video. Here's what it does step-by-step:\n",
        "\n",
        "1. **Loads the Book Image and First Video Frame**  \n",
        "   - Converts both to grayscale for feature extraction.\n",
        "\n",
        "2. **Extracts SIFT Keypoints and Descriptors**  \n",
        "   - Uses the Scale-Invariant Feature Transform (SIFT) algorithm to detect and describe keypoints in both images.\n",
        "\n",
        "3. **Matches Features Using BFMatcher with k-Nearest Neighbors**  \n",
        "   - Finds the two closest matches for each descriptor using brute-force matching.\n",
        "\n",
        "4. **Applies Lowe's Ratio Test**  \n",
        "   - Filters out poor matches by keeping only those that pass the 0.75 ratio threshold.\n",
        "\n",
        "5. **Selects the Top 50 Best Matches**  \n",
        "   - Sorts the good matches by distance and selects the 50 most accurate ones.\n",
        "\n",
        "6. **Visualizes the Matches**  \n",
        "   - Draws the top 50 matches between the book image and the video frame.\n",
        "\n",
        "This is a crucial step for establishing correspondences that can be used later for homography computation and AR overlays.\n"
      ],
      "metadata": {
        "id": "8m9nG1aELcMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Function to get top 50 SIFT matches\n",
        "def get_top_50_correspondences(book_img_path, book_video_path):\n",
        "    # Load book image\n",
        "    img1 = cv2.imread(book_img_path)\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Load first frame from video\n",
        "    cap = cv2.VideoCapture(book_video_path)\n",
        "    ret, frame = cap.read()\n",
        "    cap.release()\n",
        "    if not ret:\n",
        "        raise RuntimeError(\"Failed to read the first frame from video.\")\n",
        "    img2 = frame\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # SIFT + BFMatcher\n",
        "    sift = cv2.SIFT_create()\n",
        "    kp1, des1 = sift.detectAndCompute(img1_gray, None)\n",
        "    kp2, des2 = sift.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    bf = cv2.BFMatcher()\n",
        "    matches = bf.knnMatch(des1, des2, k=2)\n",
        "\n",
        "    # Lowe's Ratio Test\n",
        "    good = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.75 * n.distance:\n",
        "            good.append(m)\n",
        "\n",
        "    # Select top 50 matches\n",
        "    top_50_matches = sorted(good, key=lambda x: x.distance)[:50]\n",
        "\n",
        "    # Visualization\n",
        "    match_img = cv2.drawMatches(img1, kp1, img2, kp2, top_50_matches, None, flags=2)\n",
        "\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    plt.imshow(cv2.cvtColor(match_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Top 50 Correspondences between Book Image and First Video Frame\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return top_50_matches, kp1, kp2, img1, img2\n"
      ],
      "metadata": {
        "id": "wAJY1SZyKT7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Run matching\n",
        "book_image_path = r\"C:\\Users\\User\\PycharmProjects\\pythonProject5\\cv_cover.jpg\"\n",
        "book_video_path = r\"C:\\Users\\User\\PycharmProjects\\pythonProject5\\book.mov\"\n",
        "\n",
        "top_matches, kp1, kp2, img1, img2 = get_top_50_correspondences(book_image_path, book_video_path)\n"
      ],
      "metadata": {
        "id": "N12119BaKYEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔁 Computing the Homography Matrix from Point Correspondences\n",
        "\n",
        "This function `compute_homography_matrix` calculates the **homography transformation matrix (H)** from two sets of corresponding 2D points using the **Direct Linear Transform (DLT)** algorithm.\n",
        "\n",
        "#### What the Function Does:\n",
        "1. **Checks for Valid Input**  \n",
        "   - Ensures the input point sets `pts1` and `pts2` have the same shape and contain at least 4 correspondences, which is the minimum needed for computing a homography.\n",
        "\n",
        "2. **Constructs the Linear System (Matrix A)**  \n",
        "   - For each correspondence between a point in the source image `(x, y)` and the destination image `(x', y')`, two rows are added to matrix A based on the homography equation.\n",
        "\n",
        "3. **Solves Using Singular Value Decomposition (SVD)**  \n",
        "   - Uses SVD to solve the homogeneous system `Ah = 0`, where `h` contains the flattened elements of the homography matrix.\n",
        "   - The solution is taken as the last row of `V^T` (i.e., the eigenvector corresponding to the smallest singular value).\n",
        "\n",
        "4. **Reshapes and Normalizes**  \n",
        "   - Reshapes the solution vector into a 3×3 matrix `H`.\n",
        "   - Normalizes the matrix so that `H[2, 2] = 1`.\n",
        "\n",
        "#### Why It's Important:\n",
        "This homography matrix allows us to **warp one image to align with another**, which is essential for tasks like:\n",
        "- Image stitching\n",
        "- Augmented reality overlays\n",
        "- Perspective correction\n"
      ],
      "metadata": {
        "id": "aEhSZbIWL76K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Homography function\n",
        "def compute_homography_matrix(pts1, pts2):\n",
        "    assert pts1.shape == pts2.shape, \"Input point arrays must have same shape\"\n",
        "    assert pts1.shape[0] >= 4, \"At least 4 point correspondences required\"\n",
        "\n",
        "    n = pts1.shape[0]\n",
        "    A = []\n",
        "\n",
        "    for i in range(n):\n",
        "        x, y = pts1[i][0], pts1[i][1]\n",
        "        x_prime, y_prime = pts2[i][0], pts2[i][1]\n",
        "\n",
        "        A.append([-x, -y, -1, 0, 0, 0, x * x_prime, y * x_prime, x_prime])\n",
        "        A.append([0, 0, 0, -x, -y, -1, x * y_prime, y * y_prime, y_prime])\n",
        "\n",
        "    A = np.asarray(A)\n",
        "    _, _, Vt = np.linalg.svd(A)\n",
        "    H = Vt[-1].reshape((3, 3))\n",
        "\n",
        "    return H / H[2, 2]\n"
      ],
      "metadata": {
        "id": "E_WeR4MyKaqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔄 Warp Points Using a Homography Matrix (Optional Verification)\n",
        "\n",
        "The `warp_points` function applies a **homography transformation** to a set of 2D points.\n",
        "\n",
        "#### Function Purpose:\n",
        "This is a utility function used to **verify the effect of the computed homography matrix** by transforming a set of source points into the new perspective (destination space).\n",
        "\n",
        "#### How It Works:\n",
        "1. **Convert Points to Homogeneous Coordinates**  \n",
        "   - Adds a third coordinate (1) to each 2D point to make them homogeneous:  \n",
        "     \\[(x, y) → (x, y, 1)\\]\n",
        "\n",
        "2. **Apply the Homography Matrix**  \n",
        "   - Multiplies each point with the homography matrix \\(H\\) to get the transformed coordinates.\n",
        "\n",
        "3. **Normalize the Result**  \n",
        "   - Converts from homogeneous back to Cartesian coordinates by dividing by the third (homogeneous) coordinate.\n",
        "\n",
        "4. **Returns the Transformed Points**  \n",
        "   - The result is a new array of shape `(num_points, 2)` containing the warped \\(x'\\) and \\(y'\\) coordinates.\n",
        "\n",
        "#### When to Use:\n",
        "This function is helpful for:\n",
        "- Verifying that the homography correctly maps points.\n",
        "- Debugging by checking where keypoints land after transformation.\n"
      ],
      "metadata": {
        "id": "tIyb5NTsMD9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Warp point verification (optional)\n",
        "def warp_points(H, pts):\n",
        "    num_pts = pts.shape[0]\n",
        "    pts_homogeneous = np.hstack((pts, np.ones((num_pts, 1))))\n",
        "    warped = H @ pts_homogeneous.T\n",
        "    warped /= warped[2]\n",
        "    return warped[:2].T\n"
      ],
      "metadata": {
        "id": "meCU_76WKc-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Compute homography from previous matches\n",
        "pts1 = np.float32([kp1[m.queryIdx].pt for m in top_matches])\n",
        "pts2 = np.float32([kp2[m.trainIdx].pt for m in top_matches])\n",
        "\n",
        "H = compute_homography_matrix(pts1, pts2)\n",
        "print(\"Homography matrix H:\\n\", H)\n",
        "\n",
        "# Optional: verify error\n",
        "warped_pts1 = warp_points(H, pts1)\n",
        "error = np.linalg.norm(warped_pts1 - pts2, axis=1).mean()\n",
        "print(\"Mean projection error: {:.4f}\".format(error))\n"
      ],
      "metadata": {
        "id": "1qFXZtJkKf7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🗺️ Mapping Book Corners to Video Frame & Drawing Bounding Box\n",
        "\n",
        "#### 📐 `get_book_corners_in_video(book_img_path, H)`\n",
        "This function maps the four corners of the book image into the video frame using the **homography matrix** \\(H\\).\n",
        "\n",
        "##### What It Does:\n",
        "1. **Load Book Image**  \n",
        "   Reads the image to determine its dimensions.\n",
        "\n",
        "2. **Define Corners in Image Coordinates**  \n",
        "   Orders corners in this order: top-left, top-right, bottom-right, bottom-left.\n",
        "\n",
        "3. **Convert to Homogeneous Coordinates**  \n",
        "   Adds a third dimension (1) to allow for matrix multiplication with \\(H\\).\n",
        "\n",
        "4. **Apply Homography**  \n",
        "   Transforms the book corners to video frame coordinates.\n",
        "\n",
        "5. **Return**  \n",
        "   - Original corner coordinates.  \n",
        "   - Warped (mapped) corner coordinates.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🖍️ `draw_book_corners_on_frame(frame, corners, color=(0, 255, 0))`\n",
        "This function draws the **projected quadrilateral** (the book's corners) on a given video frame.\n",
        "\n",
        "##### What It Does:\n",
        "- Converts the float coordinates to integers.\n",
        "- Uses `cv2.polylines` to draw the 4-corner polygon (typically a rectangle).\n",
        "- The result is a frame with the book's outline drawn on it.\n",
        "\n",
        "##### Usage Example:\n",
        "Useful for visual debugging or creating visual overlays showing where the book is detected in each frame.\n"
      ],
      "metadata": {
        "id": "tC_BgGwOMQni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Function to compute mapped corners\n",
        "def get_book_corners_in_video(book_img_path, H):\n",
        "    book_img = cv2.imread(book_img_path)\n",
        "    h, w = book_img.shape[:2]\n",
        "    book_corners = np.array([\n",
        "        [0, 0],\n",
        "        [w - 1, 0],\n",
        "        [w - 1, h - 1],\n",
        "        [0, h - 1]\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    ones = np.ones((4, 1))\n",
        "    book_corners_hom = np.hstack([book_corners, ones])\n",
        "\n",
        "    mapped = H @ book_corners_hom.T\n",
        "    mapped /= mapped[2]\n",
        "    return book_corners, mapped[:2].T\n"
      ],
      "metadata": {
        "id": "eY0TwAygKh2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Draw mapped corners on frame\n",
        "def draw_book_corners_on_frame(frame, corners, color=(0, 255, 0)):\n",
        "    corners = np.int32(corners)\n",
        "    frame_with_box = frame.copy()\n",
        "    cv2.polylines(frame_with_box, [corners], isClosed=True, color=color, thickness=2)\n",
        "    return frame_with_box\n"
      ],
      "metadata": {
        "id": "0SvlgUcpKlAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Apply mapping and draw\n",
        "original_corners, mapped_corners = get_book_corners_in_video(book_image_path, H)\n",
        "frame_with_box = draw_book_corners_on_frame(img2, mapped_corners)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(cv2.cvtColor(frame_with_box, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Mapped Book Corners in Video Frame\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HwgJyfOXKnlL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
